// Free AI Proxy Router - Similar to g4f-ts
// This router aggregates free AI providers without API keys

import express from 'express';
import fetch from 'node-fetch';
import { Cookie } from 'tough-cookie';

const app = express();
app.use(express.json());

// ===========================================
// PROVIDER IMPLEMENTATIONS
// ===========================================

interface Message {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface Provider {
  name: string;
  models: string[];
  enabled: boolean;
  needsCookies: boolean;
  handler: (messages: Message[], model?: string) => Promise<string>;
}

// Provider 1: Phind (Free, no auth)
const phindProvider: Provider = {
  name: 'Phind',
  models: ['Phind-70B', 'gpt-4'],
  enabled: true,
  needsCookies: false,
  handler: async (messages: Message[], model = 'Phind-70B') => {
    const response = await fetch('https://https.extension.phind.com/agent/', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
      },
      body: JSON.stringify({
        additional_extension_context: '',
        allow_magic_buttons: true,
        is_vscode_extension: true,
        message_history: messages.map(m => ({
          role: m.role,
          content: m.content,
        })),
        requested_model: model,
        user_input: messages[messages.length - 1].content,
      }),
    });

    const text = await response.text();
    return text;
  },
};

// Provider 2: DeepInfra (Free tier)
const deepInfraProvider: Provider = {
  name: 'DeepInfra',
  models: ['meta-llama/Meta-Llama-3.1-70B-Instruct'],
  enabled: true,
  needsCookies: false,
  handler: async (messages: Message[], model = 'meta-llama/Meta-Llama-3.1-70B-Instruct') => {
    const response = await fetch('https://api.deepinfra.com/v1/openai/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'User-Agent': 'Mozilla/5.0',
      },
      body: JSON.stringify({
        model,
        messages,
        stream: false,
      }),
    });

    const data = await response.json();
    return data.choices[0].message.content;
  },
};

// Provider 3: You.com (Requires cookies)
const youProvider: Provider = {
  name: 'You',
  models: ['gpt-4', 'claude-3'],
  enabled: false, // Disabled by default - needs cookies
  needsCookies: true,
  handler: async (messages: Message[], model = 'gpt-4') => {
    // You need to extract cookies from browser
    const cookies = process.env.YOU_COOKIES || '';
    
    const response = await fetch('https://you.com/api/streamingSearch', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Cookie': cookies,
        'User-Agent': 'Mozilla/5.0',
      },
      body: JSON.stringify({
        q: messages[messages.length - 1].content,
        domain: 'youchat',
        chat: messages.map(m => ({
          question: m.role === 'user' ? m.content : '',
          answer: m.role === 'assistant' ? m.content : '',
        })),
      }),
    });

    const text = await response.text();
    return text;
  },
};

// Provider 4: HuggingChat (Free, needs session)
const huggingChatProvider: Provider = {
  name: 'HuggingChat',
  models: ['mistralai/Mixtral-8x7B-Instruct-v0.1'],
  enabled: true,
  needsCookies: false,
  handler: async (messages: Message[], model = 'mistralai/Mixtral-8x7B-Instruct-v0.1') => {
    // First create a conversation
    const sessionRes = await fetch('https://huggingface.co/chat/conversation', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model,
      }),
    });

    const session = await sessionRes.json();
    const conversationId = session.conversationId;

    // Send message
    const response = await fetch(`https://huggingface.co/chat/conversation/${conversationId}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        inputs: messages[messages.length - 1].content,
        parameters: {
          temperature: 0.7,
          max_new_tokens: 2048,
        },
      }),
    });

    const text = await response.text();
    return text;
  },
};

// Provider 5: GPT4All (Local inference, free)
const gpt4allProvider: Provider = {
  name: 'GPT4All',
  models: ['orca-mini-3b', 'gpt4all-falcon'],
  enabled: false, // Needs local setup
  needsCookies: false,
  handler: async (messages: Message[], model = 'orca-mini-3b') => {
    // Assumes you have GPT4All running locally on port 4891
    const response = await fetch('http://localhost:4891/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model,
        messages,
      }),
    });

    const data = await response.json();
    return data.choices[0].message.content;
  },
};

// All providers
const providers: Provider[] = [
  phindProvider,
  deepInfraProvider,
  youProvider,
  huggingChatProvider,
  gpt4allProvider,
];

// ===========================================
// ROUTER LOGIC
// ===========================================

// Get enabled providers
function getEnabledProviders(): Provider[] {
  return providers.filter(p => p.enabled);
}

// Try providers with fallback
async function tryProviders(messages: Message[], model?: string): Promise<string> {
  const enabled = getEnabledProviders();

  for (const provider of enabled) {
    try {
      console.log(`Trying provider: ${provider.name}`);
      const result = await provider.handler(messages, model);
      console.log(`âœ“ Success with ${provider.name}`);
      return result;
    } catch (error) {
      console.log(`âœ— Failed with ${provider.name}: ${error.message}`);
      continue;
    }
  }

  throw new Error('All providers failed');
}

// ===========================================
// OPENAI-COMPATIBLE API ROUTES
// ===========================================

// POST /v1/chat/completions
app.post('/v1/chat/completions', async (req, res) => {
  try {
    const { messages, model, stream = false } = req.body;

    if (!messages || !Array.isArray(messages)) {
      return res.status(400).json({
        error: {
          message: 'Invalid messages format',
          type: 'invalid_request_error',
        },
      });
    }

    const response = await tryProviders(messages, model);

    if (stream) {
      // Simulate streaming
      res.setHeader('Content-Type', 'text/event-stream');
      res.write(`data: ${JSON.stringify({
        choices: [{
          delta: { content: response },
          index: 0,
        }],
      })}\n\n`);
      res.write('data: [DONE]\n\n');
      res.end();
    } else {
      res.json({
        id: `chatcmpl-${Date.now()}`,
        object: 'chat.completion',
        created: Math.floor(Date.now() / 1000),
        model: model || 'gpt-3.5-turbo',
        choices: [{
          message: {
            role: 'assistant',
            content: response,
          },
          finish_reason: 'stop',
          index: 0,
        }],
        usage: {
          prompt_tokens: 0,
          completion_tokens: 0,
          total_tokens: 0,
        },
      });
    }
  } catch (error) {
    res.status(500).json({
      error: {
        message: error.message,
        type: 'provider_error',
      },
    });
  }
});

// GET /v1/models
app.get('/v1/models', (req, res) => {
  const models = providers
    .filter(p => p.enabled)
    .flatMap(p => p.models)
    .map(model => ({
      id: model,
      object: 'model',
      created: Date.now(),
      owned_by: 'free-proxy',
    }));

  res.json({
    object: 'list',
    data: models,
  });
});

// Health check
app.get('/health', (req, res) => {
  res.json({
    status: 'ok',
    providers: providers.map(p => ({
      name: p.name,
      enabled: p.enabled,
      models: p.models,
    })),
  });
});

// ===========================================
// COOKIE MANAGEMENT
// ===========================================

// Endpoint to set cookies for providers that need them
app.post('/set-cookies', (req, res) => {
  const { provider, cookies } = req.body;
  
  // Store cookies in environment or database
  // This is a simplified example
  process.env[`${provider.toUpperCase()}_COOKIES`] = cookies;
  
  res.json({ success: true });
});

// ===========================================
// START SERVER
// ===========================================

const PORT = process.env.PORT || 3000;

app.listen(PORT, () => {
  console.log(`ðŸš€ Free AI Proxy running on http://localhost:${PORT}`);
  console.log(`ðŸ“¡ OpenAI-compatible endpoint: http://localhost:${PORT}/v1/chat/completions`);
  console.log(`ðŸ“‹ Models endpoint: http://localhost:${PORT}/v1/models`);
  console.log(`\nEnabled providers:`);
  getEnabledProviders().forEach(p => {
    console.log(`  - ${p.name} (${p.models.join(', ')})`);
  });
});

export default app;